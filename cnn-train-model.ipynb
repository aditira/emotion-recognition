{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model CNN - Emotion Recognition\n",
    "\n",
    "Content:\n",
    "- Build the CNN Model with Keras\n",
    "- Dataset Preparation and Addition of Output Layers\n",
    "- Callbacks in Keras\n",
    "- Training the Model\n",
    "- Visualization of Training Results\n",
    "- Use the model and add conclusion\n",
    "- Collaborate with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network (CNN)** adalah salah satu jenis deep learning model yang paling umum digunakan untuk memproses gambar. CNN mampu memahami fitur kompleks dari gambar melalui proses pelatihan yang optimal. Kode di bawah adalah contoh bagaimana kita melatih model CNN untuk mengerjakan tugas pengenalan emosi dari gambar wajah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Kita menggunakan package keras untuk membangun arsitektur CNN dan kita mulai dengan model sequential. CNN ini terdiri dari 3 blok Convolutional Layers (Conv2D + MaxPooling), diikuti oleh Flatten Layer, Dense Layer dan Dropout Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secara visual, arsitektur model dapat kita lihat sebagai berikut:\n",
    "\n",
    "![Model CNN Architecture](./assets/images/backpropagation-algo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crete CNN model with Keras\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "Data augmentation adalah teknik yang digunakan untuk meningkatkan jumlah data dengan menambahkan versi modifikasi dari gambar ke dalam pool. Teknik ini memungkinkan model mempelajari data melalui berbagai titik pandang dan mengurangi overfitting.\n",
    "\n",
    "Membuat model _Convolutional Neural Network, CNN_ menggunakan library Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model sekuensial adalah jenis model yang membangun layer dalam urutan linear, di mana setiap layer memiliki tepat satu input tensor dan satu output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat layer konvolusional:\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menambahkan layer konvolusional kedalam model. Layer ini memiliki 32 filter dengan ukuran (3, 3) dan menggunakan fungsi aktivasi ReLU (Rectified Linear Unit). Lapisan ini juga menentukan bentuk input yang akan disertakan dalam model, dalam kasus ini bentuknya adalah (48, 48, 1).\n",
    "\n",
    "Lapisan konvolusi diikuti oleh layer pooling (Max Pooling) dengan ukuran pool (2,2). Layer MaxPooling digunakan untuk mengurangi dimensi spasial dari output volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu')) # tambahan \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menambahkan dua layer konvolusional tambahan dan setiap layer diikuti oleh layer MaxPooling. Filter meningkat dua kali lipat setiap kali (64 dan 128), hal ini umum dalam arsitektur CNN karena ini memungkinkan model untuk belajar fitur yang lebih kompleks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Flatten digunakan untuk mengubah input menjadi vektor 1D (mengubah semua data menjadi satu dimensi linear panjang). Ini biasanya digunakan sebelum membentuk layer Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menambahkan layer dense dengan 256 neuron dan fungsi aktivasi ReLU. Layer Dense ini secara penuh (fully) terhubung, artinya semua neuron di layer sebelumnya terhubung dengan semua neuron di layer ini.\n",
    "\n",
    "Layer Dropout juga ditambahkan setelah layer Dense tersebut, yang secara acak menyetel sebagian input ke 0 saat waktu training, yang membantu untuk mencegah overfitting. Dalam hal ini, 50% (0.5) dari input akan di-dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = 'dataset/kaggle'\n",
    "# Mendapatkan list dari semua sub-direktori\n",
    "sub_dirs = [name for name in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, name))]\n",
    "num_class = len(sub_dirs)\n",
    "print(f\"Number of classes: {num_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membaca direktori dataset dan menghitung jumlah sub-direktori (kelas) dalam dataset tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_class, activation='softmax')) # jumlah kelas emosi yang akan di prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menambahkan lapisan Dense ke model, jumlah neuron sama dengan jumlah kelas dalam dataset (num_class). Fungsi aktivasi yang digunakan adalah softmax, yang umum digunakan untuk lapisan output dalam masalah klasifikasi multi-kelas. Output dari softmax akan memberikan probabilitas untuk setiap kelas dan jumlah dari semua probabilitas akan menjadi 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengkompilasi model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengkompilasi model dengan loss function, optimizer, dan metrik.\n",
    "\n",
    "- `categorical_crossentropy` adalah loss function yang umum digunakan untuk masalah klasifikasi multi-kelas.\n",
    "- `adam` adalah jenis optimizer. Adam adalah algoritma optimasi yang dapat digunakan sebagai pengganti prosedur stochastic gradient descent klasik untuk memperbarui bobot jaringan secara iteratif berdasarkan data training.\n",
    "- `accuracy` adalah metrik yang akan digunakan untuk mengevaluasi performa model.\n",
    "\n",
    "Jadi, pembuatan model CNN sudah selesai, di mana layer output ditambahkan dan model dikompilasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "\n",
    "Kode ini digunakan untuk memuat dataset dari direktori yang ditentukan. Kami telah membagi dataset menjadi training dan test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Natural Human Face Images for Emotion Recognition - Kaggle](https://www.kaggle.com/datasets/sudarshanvaidya/random-images-for-face-emotion-recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5558 images belonging to 8 classes.\n",
      "Found 5558 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Membuat generator gambar dengan augmentasi data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=15,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # test data tetap hanya di rescale\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(dataset_path, \n",
    "                                                 target_size=(48, 48), \n",
    "                                                 batch_size=32, \n",
    "                                                 color_mode='grayscale', \n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(dataset_path, \n",
    "                                            target_size=(48, 48), \n",
    "                                            batch_size=32, \n",
    "                                            color_mode='grayscale', \n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0, 'contempt': 1, 'disgust': 2, 'fear': 3, 'happiness': 4, 'neutrality': 5, 'sadness': 6, 'surprise': 7}\n"
     ]
    }
   ],
   "source": [
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "Callbacks adalah objek khusus yang bisa Anda sisipkan ke dalam proses training untuk menyesuaikan proses tersebut atau melakukan tindakan tertentu setiap kali kondisi tertentu terpenuhi.\n",
    "\n",
    "Berikut adalah penjelasan untuk setiap bagian kode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callback `EarlyStopping` digunakan untuk menghentikan training ketika sebuah metrik tertentu berhenti meningkat. Dalam hal ini, model akan berhenti training jika tidak ada peningkatan dalam metrik yang diperiksa (defaultnya adalah loss validation) setelah 5 epoch (dengan asumsi `patience=5`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model/cnn/best_model.h5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callback `ModelCheckpoint`` digunakan untuk menyimpan model setelah setiap epoch.\n",
    "\n",
    "- `model/cnn/best_model.h5` adalah file tempat model dengan performa terbaik akan disimpan.\n",
    "- `monitor='val_loss'` berarti callback ini akan memantau loss validation dari model.\n",
    "- `verbose=1` berarti callback ini akan mencetak pesan saat model disimpan.\n",
    "- `save_best_only=True` berarti hanya model dengan loss validation terkecil yang akan disimpan. Jika False, maka model setelah setiap epoch akan disimpan.\n",
    "- `mode='auto'` berarti arah peningkatan atau penurunan metrik yang dipantau (dalam hal ini val_loss) akan otomatis dideteksi dan digunakan untuk memutuskan kapan harus menyimpan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [earlystop, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat list yang berisi kedua callback ini. Anda nantinya akan memberikan list ini sebagai argumen untuk parameter callbacks ketika memanggil method fit() untuk melatih model Anda. Callbacks dalam list ini akan dipanggil dalam urutan yang sama seperti yang ditentukan dalam list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Akhirnya, kita melatih model dengan dataset yang disiapkan menggunakan callback seperti `EarlyStopping` dan `ModelCheckpoint` untuk menghentikan pelatihan jika model tidak lagi memperbaiki hasil setelah beberapa epoch dan untuk menyimpan model dengan hasil terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 09:00:38.791220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - ETA: 0s - loss: 1.9885 - accuracy: 0.2494"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 09:01:03.560243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.96301, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 34s 188ms/step - loss: 1.9885 - accuracy: 0.2494 - val_loss: 1.9630 - val_accuracy: 0.2529\n",
      "Epoch 2/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.9353 - accuracy: 0.2736\n",
      "Epoch 2: val_loss improved from 1.96301 to 1.82490, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 35s 201ms/step - loss: 1.9353 - accuracy: 0.2736 - val_loss: 1.8249 - val_accuracy: 0.3170\n",
      "Epoch 3/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.8598 - accuracy: 0.3158\n",
      "Epoch 3: val_loss improved from 1.82490 to 1.75151, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 27s 154ms/step - loss: 1.8598 - accuracy: 0.3158 - val_loss: 1.7515 - val_accuracy: 0.3676\n",
      "Epoch 4/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.8016 - accuracy: 0.3418\n",
      "Epoch 4: val_loss improved from 1.75151 to 1.65299, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 25s 147ms/step - loss: 1.8016 - accuracy: 0.3418 - val_loss: 1.6530 - val_accuracy: 0.3914\n",
      "Epoch 5/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.7454 - accuracy: 0.3628\n",
      "Epoch 5: val_loss improved from 1.65299 to 1.62125, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 151ms/step - loss: 1.7454 - accuracy: 0.3628 - val_loss: 1.6212 - val_accuracy: 0.4075\n",
      "Epoch 6/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.6919 - accuracy: 0.3856\n",
      "Epoch 6: val_loss improved from 1.62125 to 1.57728, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 148ms/step - loss: 1.6919 - accuracy: 0.3856 - val_loss: 1.5773 - val_accuracy: 0.4330\n",
      "Epoch 7/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.6636 - accuracy: 0.3961\n",
      "Epoch 7: val_loss improved from 1.57728 to 1.51450, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 27s 155ms/step - loss: 1.6636 - accuracy: 0.3961 - val_loss: 1.5145 - val_accuracy: 0.4505\n",
      "Epoch 8/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.6267 - accuracy: 0.4162\n",
      "Epoch 8: val_loss improved from 1.51450 to 1.50612, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 149ms/step - loss: 1.6267 - accuracy: 0.4162 - val_loss: 1.5061 - val_accuracy: 0.4538\n",
      "Epoch 9/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.6160 - accuracy: 0.4184\n",
      "Epoch 9: val_loss improved from 1.50612 to 1.47917, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 25s 144ms/step - loss: 1.6160 - accuracy: 0.4184 - val_loss: 1.4792 - val_accuracy: 0.4648\n",
      "Epoch 10/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.5648 - accuracy: 0.4314\n",
      "Epoch 10: val_loss improved from 1.47917 to 1.44212, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 25s 146ms/step - loss: 1.5648 - accuracy: 0.4314 - val_loss: 1.4421 - val_accuracy: 0.4724\n",
      "Epoch 11/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.5456 - accuracy: 0.4377\n",
      "Epoch 11: val_loss improved from 1.44212 to 1.38634, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 25s 143ms/step - loss: 1.5456 - accuracy: 0.4377 - val_loss: 1.3863 - val_accuracy: 0.4944\n",
      "Epoch 12/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.5205 - accuracy: 0.4396\n",
      "Epoch 12: val_loss did not improve from 1.38634\n",
      "173/173 [==============================] - 25s 147ms/step - loss: 1.5205 - accuracy: 0.4396 - val_loss: 1.4276 - val_accuracy: 0.4819\n",
      "Epoch 13/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.5009 - accuracy: 0.4544\n",
      "Epoch 13: val_loss improved from 1.38634 to 1.37756, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 148ms/step - loss: 1.5009 - accuracy: 0.4544 - val_loss: 1.3776 - val_accuracy: 0.4930\n",
      "Epoch 14/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.4831 - accuracy: 0.4542\n",
      "Epoch 14: val_loss improved from 1.37756 to 1.35648, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 151ms/step - loss: 1.4831 - accuracy: 0.4542 - val_loss: 1.3565 - val_accuracy: 0.4971\n",
      "Epoch 15/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.4695 - accuracy: 0.4569\n",
      "Epoch 15: val_loss improved from 1.35648 to 1.34502, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 152ms/step - loss: 1.4695 - accuracy: 0.4569 - val_loss: 1.3450 - val_accuracy: 0.5042\n",
      "Epoch 16/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.4488 - accuracy: 0.4698\n",
      "Epoch 16: val_loss improved from 1.34502 to 1.31365, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 151ms/step - loss: 1.4488 - accuracy: 0.4698 - val_loss: 1.3136 - val_accuracy: 0.5182\n",
      "Epoch 17/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.4459 - accuracy: 0.4674\n",
      "Epoch 17: val_loss improved from 1.31365 to 1.27773, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 33s 189ms/step - loss: 1.4459 - accuracy: 0.4674 - val_loss: 1.2777 - val_accuracy: 0.5257\n",
      "Epoch 18/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.4242 - accuracy: 0.4725\n",
      "Epoch 18: val_loss improved from 1.27773 to 1.26163, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 35s 204ms/step - loss: 1.4242 - accuracy: 0.4725 - val_loss: 1.2616 - val_accuracy: 0.5383\n",
      "Epoch 19/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3982 - accuracy: 0.4841\n",
      "Epoch 19: val_loss did not improve from 1.26163\n",
      "173/173 [==============================] - 34s 195ms/step - loss: 1.3982 - accuracy: 0.4841 - val_loss: 1.3199 - val_accuracy: 0.5258\n",
      "Epoch 20/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.4023 - accuracy: 0.4888\n",
      "Epoch 20: val_loss did not improve from 1.26163\n",
      "173/173 [==============================] - 44s 253ms/step - loss: 1.4023 - accuracy: 0.4888 - val_loss: 1.2848 - val_accuracy: 0.5365\n",
      "Epoch 21/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3967 - accuracy: 0.4900\n",
      "Epoch 21: val_loss improved from 1.26163 to 1.25046, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 42s 245ms/step - loss: 1.3967 - accuracy: 0.4900 - val_loss: 1.2505 - val_accuracy: 0.5417\n",
      "Epoch 22/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3726 - accuracy: 0.4980\n",
      "Epoch 22: val_loss improved from 1.25046 to 1.22128, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 38s 219ms/step - loss: 1.3726 - accuracy: 0.4980 - val_loss: 1.2213 - val_accuracy: 0.5508\n",
      "Epoch 23/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3611 - accuracy: 0.4966\n",
      "Epoch 23: val_loss improved from 1.22128 to 1.18705, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 33s 191ms/step - loss: 1.3611 - accuracy: 0.4966 - val_loss: 1.1871 - val_accuracy: 0.5690\n",
      "Epoch 24/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3556 - accuracy: 0.4971\n",
      "Epoch 24: val_loss did not improve from 1.18705\n",
      "173/173 [==============================] - 37s 211ms/step - loss: 1.3556 - accuracy: 0.4971 - val_loss: 1.2088 - val_accuracy: 0.5627\n",
      "Epoch 25/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3432 - accuracy: 0.5096\n",
      "Epoch 25: val_loss did not improve from 1.18705\n",
      "173/173 [==============================] - 34s 194ms/step - loss: 1.3432 - accuracy: 0.5096 - val_loss: 1.2170 - val_accuracy: 0.5592\n",
      "Epoch 26/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3470 - accuracy: 0.5072\n",
      "Epoch 26: val_loss improved from 1.18705 to 1.17166, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 32s 186ms/step - loss: 1.3470 - accuracy: 0.5072 - val_loss: 1.1717 - val_accuracy: 0.5710\n",
      "Epoch 27/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3268 - accuracy: 0.5168\n",
      "Epoch 27: val_loss did not improve from 1.17166\n",
      "173/173 [==============================] - 28s 161ms/step - loss: 1.3268 - accuracy: 0.5168 - val_loss: 1.1750 - val_accuracy: 0.5732\n",
      "Epoch 28/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3211 - accuracy: 0.5177\n",
      "Epoch 28: val_loss improved from 1.17166 to 1.12990, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 151ms/step - loss: 1.3211 - accuracy: 0.5177 - val_loss: 1.1299 - val_accuracy: 0.5786\n",
      "Epoch 29/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3154 - accuracy: 0.5125\n",
      "Epoch 29: val_loss did not improve from 1.12990\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 1.3154 - accuracy: 0.5125 - val_loss: 1.1502 - val_accuracy: 0.5816\n",
      "Epoch 30/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3079 - accuracy: 0.5217\n",
      "Epoch 30: val_loss did not improve from 1.12990\n",
      "173/173 [==============================] - 25s 145ms/step - loss: 1.3079 - accuracy: 0.5217 - val_loss: 1.1600 - val_accuracy: 0.5732\n",
      "Epoch 31/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.3008 - accuracy: 0.5221\n",
      "Epoch 31: val_loss did not improve from 1.12990\n",
      "173/173 [==============================] - 25s 143ms/step - loss: 1.3008 - accuracy: 0.5221 - val_loss: 1.1430 - val_accuracy: 0.5755\n",
      "Epoch 32/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2909 - accuracy: 0.5259\n",
      "Epoch 32: val_loss did not improve from 1.12990\n",
      "173/173 [==============================] - 26s 152ms/step - loss: 1.2909 - accuracy: 0.5259 - val_loss: 1.1356 - val_accuracy: 0.5887\n",
      "Epoch 33/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2926 - accuracy: 0.5203\n",
      "Epoch 33: val_loss improved from 1.12990 to 1.12027, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 25s 143ms/step - loss: 1.2926 - accuracy: 0.5203 - val_loss: 1.1203 - val_accuracy: 0.5974\n",
      "Epoch 34/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2892 - accuracy: 0.5250\n",
      "Epoch 34: val_loss improved from 1.12027 to 1.10710, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 27s 157ms/step - loss: 1.2892 - accuracy: 0.5250 - val_loss: 1.1071 - val_accuracy: 0.5880\n",
      "Epoch 35/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2793 - accuracy: 0.5326\n",
      "Epoch 35: val_loss improved from 1.10710 to 1.09119, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 27s 159ms/step - loss: 1.2793 - accuracy: 0.5326 - val_loss: 1.0912 - val_accuracy: 0.5950\n",
      "Epoch 36/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2827 - accuracy: 0.5300\n",
      "Epoch 36: val_loss did not improve from 1.09119\n",
      "173/173 [==============================] - 27s 157ms/step - loss: 1.2827 - accuracy: 0.5300 - val_loss: 1.1080 - val_accuracy: 0.5842\n",
      "Epoch 37/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2655 - accuracy: 0.5355\n",
      "Epoch 37: val_loss did not improve from 1.09119\n",
      "173/173 [==============================] - 28s 162ms/step - loss: 1.2655 - accuracy: 0.5355 - val_loss: 1.1016 - val_accuracy: 0.5938\n",
      "Epoch 38/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2523 - accuracy: 0.5344\n",
      "Epoch 38: val_loss improved from 1.09119 to 1.07097, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 34s 196ms/step - loss: 1.2523 - accuracy: 0.5344 - val_loss: 1.0710 - val_accuracy: 0.5997\n",
      "Epoch 39/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2587 - accuracy: 0.5340\n",
      "Epoch 39: val_loss did not improve from 1.07097\n",
      "173/173 [==============================] - 31s 177ms/step - loss: 1.2587 - accuracy: 0.5340 - val_loss: 1.0978 - val_accuracy: 0.6082\n",
      "Epoch 40/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2310 - accuracy: 0.5472\n",
      "Epoch 40: val_loss did not improve from 1.07097\n",
      "173/173 [==============================] - 31s 180ms/step - loss: 1.2310 - accuracy: 0.5472 - val_loss: 1.0773 - val_accuracy: 0.5974\n",
      "Epoch 41/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2447 - accuracy: 0.5423\n",
      "Epoch 41: val_loss improved from 1.07097 to 1.07096, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 30s 174ms/step - loss: 1.2447 - accuracy: 0.5423 - val_loss: 1.0710 - val_accuracy: 0.6022\n",
      "Epoch 42/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2122 - accuracy: 0.5516\n",
      "Epoch 42: val_loss improved from 1.07096 to 1.02816, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 32s 184ms/step - loss: 1.2122 - accuracy: 0.5516 - val_loss: 1.0282 - val_accuracy: 0.6205\n",
      "Epoch 43/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2435 - accuracy: 0.5389\n",
      "Epoch 43: val_loss did not improve from 1.02816\n",
      "173/173 [==============================] - 31s 179ms/step - loss: 1.2435 - accuracy: 0.5389 - val_loss: 1.0410 - val_accuracy: 0.6227\n",
      "Epoch 44/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2318 - accuracy: 0.5492\n",
      "Epoch 44: val_loss did not improve from 1.02816\n",
      "173/173 [==============================] - 27s 154ms/step - loss: 1.2318 - accuracy: 0.5492 - val_loss: 1.0508 - val_accuracy: 0.6111\n",
      "Epoch 45/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2191 - accuracy: 0.5487\n",
      "Epoch 45: val_loss improved from 1.02816 to 1.00643, saving model to model/cnn/best_model.h5\n",
      "173/173 [==============================] - 26s 148ms/step - loss: 1.2191 - accuracy: 0.5487 - val_loss: 1.0064 - val_accuracy: 0.6286\n",
      "Epoch 46/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2247 - accuracy: 0.5519\n",
      "Epoch 46: val_loss did not improve from 1.00643\n",
      "173/173 [==============================] - 26s 151ms/step - loss: 1.2247 - accuracy: 0.5519 - val_loss: 1.0161 - val_accuracy: 0.6290\n",
      "Epoch 47/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2093 - accuracy: 0.5563\n",
      "Epoch 47: val_loss did not improve from 1.00643\n",
      "173/173 [==============================] - 25s 146ms/step - loss: 1.2093 - accuracy: 0.5563 - val_loss: 1.0421 - val_accuracy: 0.6178\n",
      "Epoch 48/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2098 - accuracy: 0.5528\n",
      "Epoch 48: val_loss did not improve from 1.00643\n",
      "173/173 [==============================] - 17s 98ms/step - loss: 1.2098 - accuracy: 0.5528 - val_loss: 1.0616 - val_accuracy: 0.6109\n",
      "Epoch 49/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.2000 - accuracy: 0.5599\n",
      "Epoch 49: val_loss did not improve from 1.00643\n",
      "173/173 [==============================] - 14s 80ms/step - loss: 1.2000 - accuracy: 0.5599 - val_loss: 1.0387 - val_accuracy: 0.6243\n",
      "Epoch 50/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 1.1890 - accuracy: 0.5610\n",
      "Epoch 50: val_loss did not improve from 1.00643\n",
      "173/173 [==============================] - 13s 78ms/step - loss: 1.1890 - accuracy: 0.5610 - val_loss: 1.0234 - val_accuracy: 0.6228\n"
     ]
    }
   ],
   "source": [
    "# Melakukan training model dengan data yang sudah di augmentasi\n",
    "history = model.fit(training_set, \n",
    "          steps_per_epoch=training_set.samples//32, \n",
    "          validation_data=test_set, \n",
    "          validation_steps=test_set.samples//32, \n",
    "          epochs=50, # Bisa menambahkan lebih banyak epoch karena kita menggunakan callback\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips:** ada beberapa hal yang bisa dilakukan untuk meningkatkan kinerja model:\n",
    "\n",
    "- **Tambahkan lebih banyak data**: Jika Anda memiliki lebih banyak data, model dapat belajar pola yang lebih bervariasi, yang dapat meningkatkan akurasi.\n",
    "- **Data augmentation**: Jika Anda tidak memiliki cukup data, Anda bisa mencoba teknik augmentasi data seperti flipping, rotating, zooming, dll.\n",
    "- **Tambahkan lebih banyak layer atau ubah parameter**: Anda bisa mencoba menambahkan lebih banyak layer konvolusi atau dense, atau mengubah jumlah neuron dalam layer tersebut. Anda juga bisa menambahkan atau mengubah dropout rate.\n",
    "- **Epoch**: Anda bisa mencoba meningkatkan jumlah epoch. Dengan melakukan lebih banyak iterasi, model mungkin dapat belajar lebih baik. Namun perhatikan untuk jangan sampai overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize change in loss and model accuracy\n",
    "\n",
    "Memvisualisasikan perubahan loss (kerugian) dan akurasi model selama proses training dan validasi dengan menggunakan `Matplotlib`, library visualisasi data di Python. `history` adalah objek yang dikembalikan oleh method `fit()` saat melatih model dan berisi catatan loss dan metrik lainnya setiap kali epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend([\"Train\", \"Loss\"], loc=\"upper left\")\n",
    "plt.title('Loss')\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend([\"Train\", \"Loss\"], loc=\"upper left\")\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jadi, kode ini pada dasarnya membuat dua plot: satu untuk loss dan satu untuk akurasi. Untuk setiap plot, nilai training dan validasi ditampilkan. Ini adalah cara yang baik untuk memvisualisasikan proses training dan untuk melihat apakah model overfit (jika loss training menurun tetapi loss validasi mulai meningkat) atau underfit (jika loss training dan validasi masih tinggi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 159ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.4565222e-05 5.3079011e-06 9.0791218e-05 2.9964902e-05 9.9950671e-01\n",
      " 8.3064278e-06 7.2468712e-05 2.5189447e-04]\n",
      "happiness: 99.95067119598389%\n",
      "surprise: 0.0251894467510283%\n",
      "disgust: 0.009079121809918433%\n",
      "sadness: 0.007246871246024966%\n",
      "anger: 0.0034565222449600697%\n",
      "fear: 0.0029964901841594838%\n",
      "neutrality: 0.0008306427844217978%\n",
      "contempt: 0.0005307901119522285%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model/master/emotion_model.h5')\n",
    "\n",
    "img_path = 'dataset/kaggle/happiness/2Q__ (5)_face.png'\n",
    "# Load image\n",
    "img = load_img(img_path, target_size=(48, 48), color_mode='grayscale')\n",
    "\n",
    "# Convert image to array and expand dimension\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Standardize (Rescale pixel values)\n",
    "test_data = img_array / 255.0\n",
    "\n",
    "# Make prediction\n",
    "preds = model.predict(test_data)\n",
    "display(Image(img_path))\n",
    "print(preds[0])\n",
    "slov_res ={}\n",
    "for i in training_set.class_indices:\n",
    "    slov_res[i] = preds[0][training_set.class_indices[i]]\n",
    "    \n",
    "\n",
    "sorted_keys = sorted(slov_res, key=slov_res.get, reverse = True)\n",
    "sorted_dict = {}\n",
    "for w in sorted_keys:\n",
    "    sorted_dict[w] = slov_res[w]\n",
    "    \n",
    "for i in sorted_dict:\n",
    "    print(str(i) + ': ' + str(sorted_dict[i]*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kesimpulan:\n",
      "Gambar tersebut sebagian besar menunjukkan emosi happiness dengan tingkat keyakinan 99.95067119598389%.\n",
      "Selain itu, model juga merasakan emosi surprise dengan tingkat keyakinan 0.0251894467510283%.\n"
     ]
    }
   ],
   "source": [
    "top_emotion = list(sorted_dict.keys())[0]\n",
    "top_emotion_percentage = sorted_dict[top_emotion]*100\n",
    "second_emotion = list(sorted_dict.keys())[1]\n",
    "second_emotion_percentage = sorted_dict[second_emotion]*100\n",
    "\n",
    "print(f\"\\nKesimpulan:\")\n",
    "print(f\"Gambar tersebut sebagian besar menunjukkan emosi {top_emotion} dengan tingkat keyakinan {top_emotion_percentage}%.\")\n",
    "print(f\"Selain itu, model juga merasakan emosi {second_emotion} dengan tingkat keyakinan {second_emotion_percentage}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborate with ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's great to hear that! Being happy is a wonderful feeling. Is there anything specific you would like assistance with related to happiness?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Generate a response\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"The person seems to be \" + top_emotion}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get the response\n",
    "output = response['choices'][0]['message']['content']\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
